{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0dddcc-ecc5-4a14-9bfb-6a0852d6661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93bc2479-6ef4-4269-ae2e-5a4a3df701a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import stats\n",
    "import time\n",
    "\n",
    "class Dealer:\n",
    "    def __init__(self, df, min_lift, min_precedent_support, consequent, consequent_value, seed):\n",
    "        random.seed(seed)\n",
    "        print(\"Creating dealer...\")\n",
    "        reorder_cols = list(df.columns)\n",
    "        reorder_cols.remove(consequent)\n",
    "        reorder_cols.append(consequent)\n",
    "        self.df = df[reorder_cols]\n",
    "        self.consequent = consequent\n",
    "        self.consequent_value = consequent_value\n",
    "        self.consequent_support = len(df[df[consequent] == consequent_value].index)/len(df.index)\n",
    "        self.boundaries, self.dict_num_col, self.dicts_num_val, self.dicts_val_num = self.generate_dicts()\n",
    "        self.grouped_indexes = self.generate_groups()\n",
    "        self.genotype_order = [col for col in self.df.columns if col != self.consequent]\n",
    "        print(f'TamaÃ±o del espacio de busqueda: {np.array([b+1 for b in self.boundaries]).prod()} precedentes')\n",
    "        self.generations_history = []\n",
    "        self.seen_fenotypes = {}\n",
    "        #self.run(gen_size = 200, num_generations = num_generations)\n",
    "        \n",
    "        \n",
    "    def run(self, gen_size = 200, num_generations = 5):\n",
    "        print('run')\n",
    "        generation = [self.generate_random_genotype() for _ in range(gen_size)]\n",
    "        for i in range(num_generations):\n",
    "            start = time.time()\n",
    "            stats = [self.fitness(genotype) for genotype in generation]\n",
    "            print(f'Calculating stats took: {time.time()-start} seconds')\n",
    "            fitnesses = np.array([stat['fitness'] for stat in stats])\n",
    "            lifts = np.array([stat['lift'] for stat in stats])\n",
    "            supports = np.array([stat['precedent_support'] for stat in stats])\n",
    "            fishers = np.array([stat['fisher'] for stat in stats if 'fisher' in stat])\n",
    "            self.generations_history.append(generation.copy())\n",
    "            generation_resume = f'Generation {i} (size = {len(generation)}):\\nFitness: max={fitnesses.max()}\\\n",
    "                mean={fitnesses.mean()} min={fitnesses.min()}.\\nBest fenotype: {generation[fitnesses.argmax()]}\\\n",
    "                {self.decode_fenotype(generation[fitnesses.argmax()])} lift: {lifts[fitnesses.argmax()]}\\\n",
    "                fisher: {fishers[fitnesses.argmax()]}\\n'\n",
    "            print(generation_resume)\n",
    "            if i == num_generations: break\n",
    "            print(f'\\tentering reproduction phase of generation {i}')\n",
    "            generation = self.reproduction(generation, fitnesses,lifts, supports)\n",
    "            print(f'\\tentering mutation phase of generation {i}')\n",
    "            generation = self.mutations(generation)\n",
    "            \n",
    "        self.generation = generation\n",
    "    \n",
    "    def run_1(self):\n",
    "        generation = self.generation\n",
    "        start = time.time()\n",
    "        stats = [self.fitness(genotype) for genotype in generation]\n",
    "        print(f'Calculating stats took: {time.time()-start} seconds')\n",
    "        fitnesses = np.array([stat['fitness'] for stat in stats])\n",
    "        lifts = np.array([stat['lift'] for stat in stats])\n",
    "        supports = np.array([stat['precedent_support'] for stat in stats])\n",
    "        fishers = np.array([stat['fisher'] for stat in stats if 'fisher' in stat])\n",
    "        i = len(self.generations_history)\n",
    "        generation_resume = f'Generation {i} (size = {len(generation)}):\\nFitness: max={fitnesses.max()}\\\n",
    "            mean={fitnesses.mean()} min={fitnesses.min()}.\\nBest fenotype: {generation[fitnesses.argmax()]}\\\n",
    "            {self.decode_fenotype(generation[fitnesses.argmax()])} lift: {lifts[fitnesses.argmax()]}\\\n",
    "            fisher: {fishers[fitnesses.argmax()]}\\n'\n",
    "        print(generation_resume)\n",
    "        print(f'\\tentering reproduction phase of generation {i}')\n",
    "        generation = self.reproduction(generation, fitnesses,lifts, supports)\n",
    "        print(f'\\tentering mutation phase of generation {i}')\n",
    "        generation = self.mutations(generation)\n",
    "        self.generations_history.append(generation.copy())\n",
    "            \n",
    "        self.generation = generation\n",
    "        \n",
    "            \n",
    "        \n",
    "    def tournament_parent(self, generation, fitnesses ,lifts, supports, T = 2):\n",
    "        selected = [random.randint(0, len(generation)-1) for _ in range(T)]\n",
    "        winner = generation[selected[0]]\n",
    "        best_fitness = fitnesses[selected[0]]\n",
    "        for sel in selected[1:]:\n",
    "            if fitnesses[sel]>best_fitness:\n",
    "                winner = generation[sel]\n",
    "                best_fitness = lifts[sel]\n",
    "        return winner\n",
    "    \n",
    "    def reproduction(self, generation, fitnesses, lifts, supports, T = 2):\n",
    "        next_generation = []\n",
    "        start = time.time()\n",
    "        while(len(next_generation) < len(generation)):\n",
    "            if len(next_generation)%20 == 0:\n",
    "                print(f'\\t{len(next_generation)}/{len(generation)}  {int(time.time() - start)} segundos')\n",
    "            parent1 = self.tournament_parent(generation, fitnesses, lifts, supports, T = T)\n",
    "            parent2 = self.tournament_parent(generation, fitnesses, lifts, supports, T = T)\n",
    "            gen_pos = random.randint(1, len(parent1)-1)\n",
    "            son1 = parent1[:gen_pos] + parent2[gen_pos:]\n",
    "            son2 = parent2[:gen_pos] + parent1[gen_pos:]\n",
    "            pool = [parent1, parent2, son1, son2]\n",
    "            pool_val = {tuple(son1): self.fitness(son1)['fitness'], tuple(son2): self.fitness(son2)['fitness']}\n",
    "            pool_val[tuple(parent1)] = fitnesses[generation.index(parent1)]\n",
    "            pool_val[tuple(parent2)] = fitnesses[generation.index(parent2)]\n",
    "            pool = [p for p in pool if sum(p) != 0]\n",
    "            pool.sort(key = lambda x: pool_val[tuple(x)], reverse = True)           \n",
    "            next_generation += pool[:2] \n",
    "        return next_generation\n",
    "    \n",
    "    def mutations(self, generation, mutation_probability = .2):\n",
    "        next_generation = generation.copy()\n",
    "        for i in range(len(generation)):\n",
    "            if random.random() < mutation_probability:\n",
    "                mutated_position = random.randint(0, len(self.boundaries) - 1)\n",
    "                next_generation[i][mutated_position] = random.randint(0, self.boundaries[mutated_position])\n",
    "                if sum(next_generation[i]) == 0:\n",
    "                    next_generation[i][mutated_position] = random.randint(1, self.boundaries[mutated_position])\n",
    "        return next_generation\n",
    "        \n",
    "    \n",
    "    def generate_groups(self):\n",
    "        '''Funcion auxiliar para el constructor'''\n",
    "        grouped_indexes = {}\n",
    "        for col in self.df.columns:\n",
    "            grouped_indexes[col] = {group:set(lista) for group,lista in self.df.groupby(col).groups.items()}\n",
    "        return grouped_indexes\n",
    "        \n",
    "        \n",
    "    def generate_dicts(self):\n",
    "        '''Funcion auxiliar para el constructor'''\n",
    "        dict_num_col = {}\n",
    "        dicts_num_val = {}\n",
    "        dicts_val_num = {}\n",
    "        boundaries = []\n",
    "        for index,col in enumerate(self.df.columns):\n",
    "            dict_num_col[index] = col\n",
    "            \n",
    "            if col != self.consequent:\n",
    "                \n",
    "                boundaries.append(len(self.df[self.df[col].notna()][col].unique()))\n",
    "                dict_num_val = {i+1:val for i,val in enumerate(self.df[self.df[col].notna()][col].unique())}\n",
    "                dict_val_num = {val:i+1 for i,val in enumerate(self.df[self.df[col].notna()][col].unique())}\n",
    "                dicts_num_val[col] = dict_num_val\n",
    "                dicts_val_num[col] = dict_val_num\n",
    "        return boundaries, dict_num_col, dicts_num_val, dicts_val_num\n",
    "    \n",
    "    def decode_fenotype(self, fenotype):\n",
    "        result = []\n",
    "        for i,f in enumerate(fenotype):\n",
    "            if f != 0:\n",
    "                result.append(self.dicts_num_val[self.genotype_order[i]][f])\n",
    "        return result\n",
    "      \n",
    "        \n",
    "    def generate_random_genotype(self, probability_of_zero = .4):\n",
    "        genotype = [0]*len(self.boundaries)\n",
    "        while(sum(genotype) == 0):\n",
    "            genotype = [0]*len(self.boundaries)\n",
    "            for i in range(len(self.boundaries)):\n",
    "                if random.random() > probability_of_zero:\n",
    "                    genotype[i] = random.randint(1,self.boundaries[i])\n",
    "        return genotype\n",
    "    \n",
    "    def fitness(self, fenotype) -> dict:\n",
    "        return self.fitness_lift_if_fisher(fenotype)\n",
    "    \n",
    "    def fitness_lift_times_support(self, fenotype):\n",
    "        '''funcion de fitness que multiplica el lift de la regla por el soporte del precedente'''\n",
    "        _, lift, precedent_support = self.fitness_lift(fenotype)\n",
    "        return lift*precedent_support, lift, precedent_support\n",
    "    \n",
    "    def fitness_lift_if_fisher(self, fenotype) -> dict:\n",
    "        key = tuple(fenotype)\n",
    "        if key in self.seen_fenotypes:\n",
    "            return self.seen_fenotypes[key]\n",
    "        precedent_set = set(self.df.index)\n",
    "        for i in range(len(fenotype)):\n",
    "            if fenotype[i] != 0:\n",
    "                col_name = self.dict_num_col[i]\n",
    "                val = self.dicts_num_val[col_name][fenotype[i]]\n",
    "                precedent_set = precedent_set.intersection(self.grouped_indexes[col_name][val])\n",
    "        _a_set = set(self.df.index) - precedent_set\n",
    "        _ab_set = _a_set.intersection(self.grouped_indexes[self.consequent][self.consequent_value])\n",
    "        rule_set = precedent_set.intersection(self.grouped_indexes[self.consequent][self.consequent_value])\n",
    "        # Defining contingency table values\n",
    "        ab = len(rule_set)\n",
    "        a_b = len(precedent_set) - ab\n",
    "        _ab = len(_ab_set)\n",
    "        _a_b = len(_a_set) - _ab\n",
    "        fisher = stats.fisher_exact(table=[[ab,_ab],[a_b,_a_b]], alternative=\"less\")[1]\n",
    "        try:\n",
    "            confidence = len(rule_set)/len(precedent_set)\n",
    "        except:\n",
    "            confidence = 0\n",
    "        lift = confidence/self.consequent_support\n",
    "        precedent_support = len(precedent_set)/len(self.df.index)\n",
    "        personas = round(precedent_support*len(self.df.index))\n",
    "        if fisher < .05 and personas >= 25:\n",
    "            if lift > 1:\n",
    "                fitness = lift + (lift-1)\n",
    "            else:\n",
    "                if lift != 0:\n",
    "                    fitness = 1 / lift\n",
    "                else:\n",
    "                    fitness = 10 #Not going to happen\n",
    "        else:\n",
    "            fitness = - fisher\n",
    "        self.seen_fenotypes[key] = {\"fitness\": fitness, \"lift\": lift, \"precedent_support\": precedent_support, \"fisher\": fisher}\n",
    "        return self.seen_fenotypes[key]\n",
    "        \n",
    "    \n",
    "    def fitness_fisher(self, fenotype):\n",
    "        precedent_set = set(self.df.index)\n",
    "        for i in range(len(fenotype)):\n",
    "            if fenotype[i] != 0:\n",
    "                col_name = self.dict_num_col[i]\n",
    "                val = self.dicts_num_val[col_name][fenotype[i]]\n",
    "                precedent_set = precedent_set.intersection(self.grouped_indexes[col_name][val])\n",
    "        _a_set = set(self.df.index) - precedent_set\n",
    "        _ab_set = _a_set.intersection(self.grouped_indexes[self.consequent][self.consequent_value])\n",
    "        rule_set = precedent_set.intersection(self.grouped_indexes[self.consequent][self.consequent_value])\n",
    "        # Defining contingency table values\n",
    "        ab = len(rule_set)\n",
    "        a_b = len(precedent_set) - ab\n",
    "        _ab = len(_ab_set)\n",
    "        _a_b = len(_a_set) - _ab\n",
    "        fisher = stats.fisher_exact(table=[[ab,_ab],[a_b,_a_b]], alternative=\"less\")[1]\n",
    "        \n",
    "        try:\n",
    "            confidence = len(rule_set)/len(precedent_set)\n",
    "        except:\n",
    "            confidence = 0\n",
    "        lift = confidence/self.consequent_support\n",
    "        precedent_support = len(precedent_set)/len(self.df.index)\n",
    "        fitness = -fisher\n",
    "        return fitness, lift, precedent_support\n",
    "            \n",
    "    def fitness_lift(self, fenotype): # Genotype example [0,2,1, 0, 0] = {20-30, masc}\n",
    "        '''\n",
    "        \n",
    "        Devuelve el lift de la regla y el soporte del precedente\n",
    "        '''\n",
    "        precedent_set = set(self.df.index)\n",
    "        for i in range(len(fenotype)):\n",
    "            if fenotype[i] != 0:\n",
    "                col_name = self.dict_num_col[i]\n",
    "                val = self.dicts_num_val[col_name][fenotype[i]]\n",
    "                precedent_set = precedent_set.intersection(self.grouped_indexes[col_name][val])\n",
    "                \n",
    "        rule_set = precedent_set.intersection(self.grouped_indexes[self.consequent][self.consequent_value])\n",
    "        try:\n",
    "            confidence = len(rule_set)/len(precedent_set)\n",
    "        except:\n",
    "            confidence = 0\n",
    "        lift = confidence/self.consequent_support\n",
    "        precedent_support = len(precedent_set)/len(self.df.index)\n",
    "        fitness = lift\n",
    "        return fitness, lift, precedent_support\n",
    "    \n",
    "    def describe_generation(self, generation = None):\n",
    "        if not generation:\n",
    "            generation = self.generation\n",
    "        stats = {tuple(fenotype):self.fitness(fenotype) for fenotype in generation}\n",
    "        sorted_generation = sorted(generation, key = lambda x: stats[tuple(x)]['fitness'], reverse = True)\n",
    "\n",
    "        # fitnesses = stats[:,0]\n",
    "        # lifts = stats[:,1]\n",
    "        # supports = stats[:,2]  \n",
    "        \n",
    "        fitnesses = np.array([stats[tuple(fen)]['fitness'] for fen in sorted_generation])\n",
    "        lifts = np.array([stats[tuple(fen)]['lift'] for fen in sorted_generation])\n",
    "        supports = np.array([stats[tuple(fen)]['precedent_support'] for fen in sorted_generation])\n",
    "        fishers = np.array([stats[tuple(fen)]['fisher'] for fen in sorted_generation])\n",
    "        \n",
    "        print(f'Current generation ({len(self.generation)} pop)')\n",
    "        print(f\"fitness -> mean:{fitnesses.mean()}, max:{fitnesses.max()}, min:{fitnesses.min()}\")\n",
    "        print(f\"lift -> mean:{lifts.mean()}, max:{lifts.max()}, min:{lifts.min()}\")\n",
    "        print(f\"support -> mean:{supports.mean()}, max:{supports.max()}, min:{supports.min()}\")\n",
    "        print(f\"fisher -> mean:{fishers.mean()}, max:{fishers.max()}, min:{fishers.min()}\") \n",
    "        printed_gen_set = set()\n",
    "        for gen in sorted_generation:\n",
    "            key = tuple(gen)\n",
    "            if key not in printed_gen_set:\n",
    "                fitness = stats[key]['fitness']\n",
    "                lift = stats[key]['lift']\n",
    "                precedent_support = stats[key]['precedent_support']\n",
    "                fisher = stats[key]['fisher']\n",
    "\n",
    "                print(f'\\t{self.decode_fenotype(gen)}\\n\\t\\tfitness:{fitness}, lift:{lift}, fisher:{fisher},precedent_support:{round(precedent_support*len(self.df.index))}personas ({round(precedent_support, 8)}), appearances: {list(stats).count(key)}')\n",
    "                printed_gen_set.add(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9236ae23-a703-412f-887f-bac4ef17585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_mining(transactions, **kwargs):\n",
    "    min_lift = kwargs.get('min_lift', 1.01)\n",
    "    min_precedent_support = kwargs.get('min_precedent_support', .01)\n",
    "    consequent = kwargs.get('consequent')\n",
    "    consequent_value = kwargs.get('consequent_value', 1)\n",
    "    seed = kwargs.get('consequent_value', 42)\n",
    "    return Dealer(transactions, min_lift, min_precedent_support, consequent, consequent_value, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b643f8af-71cd-4433-a962-a6f00a2306a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__== \"__main__\":\n",
    "    seed = 42\n",
    "    file = \"gs://uc3m-segmentacion-clientes/CSV-Hugo/master_beta_faltafinanciacion.csv\"\n",
    "    columns_to_use = ['provincia', 'edad', 'genero', 'renta_bruta_media', 'tipo_servicio', 'tipo_facturacion','tarifa_id','coste_tarifa','tipo_venta', 'operador_portabilidad', 'num_ventas','alarma','servicios_adicionales', 'financia', 'energia']\n",
    "    \n",
    "    transaction_df = pd.read_csv(file).sample(frac = 1, random_state = seed)\n",
    "    transaction_df.drop_duplicates(keep = 'first', subset=[\"customer_id\"], inplace=True)\n",
    "    transaction_df = transaction_df[columns_to_use]\n",
    "    print(f\"Read dataframe: {len(transaction_df.index)} rows\")\n",
    "    d = genetic_mining(transaction_df, min_precedent_support = .01,min_lift = 1.02, consequent = \"financia\", consequent_value = \"financia\", seed = seed)\n",
    "    d.run(num_generations = 50)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m102"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
